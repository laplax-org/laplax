{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "# Introduction to `laplax` for regression tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial follows the `laplace-torch` regression tutorial. It is a great start to visually understand the posterior Gaussian Process kernel induced by the weight-space Laplace approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "from flax import nnx\n",
    "from helper import DataLoader, get_sinusoid_example\n",
    "from plotting import plot_regression_with_uncertainty\n",
    "\n",
    "n_epochs = 1000\n",
    "key = jax.random.key(0)\n",
    "\n",
    "# Sample toy data example\n",
    "num_training_samples = 150\n",
    "num_calibration_samples = 50\n",
    "num_test_samples = 100\n",
    "\n",
    "batch_size = 20\n",
    "X_train, y_train, X_valid, y_valid, X_test, y_test = get_sinusoid_example(\n",
    "    num_train_data=num_training_samples,\n",
    "    num_valid_data=num_calibration_samples,\n",
    "    num_test_data=num_test_samples,\n",
    "    sigma_noise=0.3,\n",
    "    rng_key=jax.random.key(0)\n",
    ")\n",
    "train_loader = DataLoader(X_train, y_train, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "## Training a MAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we use `flax.nnx` for training a neural network. Other libraries (e.g., `equinox` or `flax.linen`) should also work out of the box if they are brought into the form of `model_fn` function (taking two arguments, `input`, and `params`) and a `params` PyTree containing the learned parameters you want to do inference over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train MAP model\n",
    "class Model(nnx.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, rngs):\n",
    "        self.linear1 = nnx.Linear(in_channels, hidden_channels, rngs=rngs)\n",
    "        self.linear2 = nnx.Linear(hidden_channels, out_channels, rngs=rngs)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = nnx.tanh(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Initialize model\n",
    "model = Model(in_channels=1, hidden_channels=50, out_channels=1, rngs=nnx.Rngs(0))\n",
    "\n",
    "\n",
    "# Set loss function\n",
    "def criterion(x, y):\n",
    "    return jnp.sum((x - y) ** 2)\n",
    "\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = nnx.Optimizer(model, optax.adamw(1e-2))  # Reference sharing\n",
    "\n",
    "\n",
    "@nnx.jit\n",
    "def train_step(model, optimizer, x, y):\n",
    "    def loss_fn(model):\n",
    "        y_pred = model(x)  # Call methods directly\n",
    "        return criterion(y, y_pred)\n",
    "\n",
    "    loss, grads = nnx.value_and_grad(loss_fn)(model)\n",
    "    optimizer.update(grads)  # Inplace updates\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    for x_tr, y_tr in train_loader:\n",
    "        loss = train_step(model, optimizer, x_tr, y_tr)\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"[epoch {epoch}]: loss: {loss:.4f}\")\n",
    "\n",
    "print(f\"Final loss: {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup curvature matrix-vector product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from laplax.curv import create_ggn_mv\n",
    "from laplax.util.loader import input_target_split\n",
    "\n",
    "# Create GGN\n",
    "graph_def, params = nnx.split(model)\n",
    "\n",
    "\n",
    "def model_fn(input, params):\n",
    "    return nnx.call((graph_def, params))(input)[0]\n",
    "\n",
    "\n",
    "train_batch = {\"input\": X_train, \"target\": y_train}\n",
    "\n",
    "ggn_mv = create_ggn_mv(\n",
    "    model_fn,\n",
    "    params,\n",
    "    train_batch,\n",
    "    loss_fn=\"mse\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this small toy example, we can dense the curvature matrix-vector product. We start by wrapping the matrix-vector product to accept normal unit vectors (of the size of flattened parameters). This will help us visualize the GGN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import SymLogNorm\n",
    "\n",
    "from laplax.util.flatten import flatten_function\n",
    "from laplax.util.mv import to_dense\n",
    "from laplax.util.tree import get_size\n",
    "\n",
    "ggn_mv_wrapped = flatten_function(ggn_mv, params)\n",
    "arr = to_dense(ggn_mv_wrapped, layout=get_size(params))\n",
    "\n",
    "\n",
    "plt.imshow(arr, norm=SymLogNorm(linthresh=1e-2, linscale=1))\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curvature estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, we can not afford to dense and continue computations with the GGN. Therefore, various strategies for estimating the curvature exist. Within this package we have: `full` (obvious), `diagonal` and low_rank. For the latter, we support finding the low rank representation using `lanczos` or `lobpcg`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Create dropdown for library selection.\n",
    "lib_dropdown = widgets.Dropdown(\n",
    "    options=['full', 'diagonal', 'lanczos', 'lobpcg'],\n",
    "    value='full',\n",
    "    description='Curv. est.:',\n",
    ")\n",
    "display(lib_dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Curv. est.:\", lib_dropdown.value)\n",
    "curv_type = lib_dropdown.value\n",
    "low_rank_args = {\n",
    "    \"key\": jax.random.key(20),\n",
    "    \"rank\": 50,\n",
    "    \"mv_jittable\": True,\n",
    "}\n",
    "curv_args = {} if curv_type in {\"full\", \"diagonal\"} else low_rank_args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from laplax.curv import estimate_curvature\n",
    "\n",
    "curv_estimate = estimate_curvature(\n",
    "    curv_type=curv_type,\n",
    "    mv=ggn_mv,\n",
    "    layout=params,\n",
    "    **curv_args,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a posterior_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create a `posterior_fn` that takes `prior_arguments` and returns a posterior distribution over the weights. If we have already an estimation of the curvature, then we can directly set the posterior function. Otherwise both functions can also be executed at once using the `laplax.curv.create_posterior_fn`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from laplax.curv.cov import set_posterior_fn\n",
    "\n",
    "posterior_fn = set_posterior_fn(curv_type, curv_estimate, layout=params)\n",
    "\n",
    "# # Alternatively, we can create the posterior function from scratch, if no curvature\n",
    "# # estimation is available.\n",
    "# # Create Posterior\n",
    "# posterior_fn = create_posterior_fn(\n",
    "#     curv_type=curv_type,\n",
    "#     mv=ggn_mv,\n",
    "#     layout=params,\n",
    "#     **curv_args,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to pushforward the weight space uncertainty?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three ideas for pushing forward weight space uncertainty.\n",
    "\n",
    "1. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linearized push-forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "from laplax.eval.pushforward import (\n",
    "    lin_pred_mean,\n",
    "    lin_pred_var,\n",
    "    lin_setup,\n",
    "    set_lin_pushforward,\n",
    ")\n",
    "\n",
    "# Setup linearized pushforward\n",
    "set_prob_predictive = partial(\n",
    "    set_lin_pushforward,\n",
    "    model_fn=model_fn,\n",
    "    mean_params=params,\n",
    "    posterior_fn=posterior_fn,\n",
    "    pushforward_fns=[\n",
    "        lin_setup,\n",
    "        lin_pred_mean,\n",
    "        lin_pred_var,\n",
    "    ],\n",
    ")\n",
    "prior_arguments = {\"prior_prec\": 1.0}  # Choose any prior precision.\n",
    "prob_predictive = set_prob_predictive(\n",
    "    prior_arguments=prior_arguments,\n",
    ")\n",
    "\n",
    "X_range = jnp.linspace(0, 8, 200).reshape(200, 1)\n",
    "pred = jax.vmap(prob_predictive)(X_range)\n",
    "pred_mean = pred[\"pred_mean\"][:, 0]\n",
    "pred_var = pred[\"pred_var\"][:, 0]\n",
    "print(pred_mean.shape, pred_var.shape)\n",
    "plot_regression_with_uncertainty(\n",
    "    train_input=train_batch[\"input\"],\n",
    "    train_target=train_batch[\"target\"],\n",
    "    X_grid=X_range,\n",
    "    Y_pred=pred_mean,\n",
    "    Y_var=pred_var,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-linear push-forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "from laplax.eval.pushforward import (\n",
    "    nonlin_pred_mean,\n",
    "    nonlin_pred_var,\n",
    "    nonlin_setup,\n",
    "    set_nonlin_pushforward,\n",
    ")\n",
    "\n",
    "# Setup linearized pushforward\n",
    "set_nonlin_prob_predictive = partial(\n",
    "    set_nonlin_pushforward,\n",
    "    model_fn=model_fn,\n",
    "    mean_params=params,\n",
    "    posterior_fn=posterior_fn,\n",
    "    pushforward_fns=[\n",
    "        nonlin_setup,\n",
    "        nonlin_pred_mean,\n",
    "        nonlin_pred_var,\n",
    "    ],\n",
    "    key=jax.random.key(42),\n",
    "    num_samples=10000,\n",
    ")\n",
    "prior_arguments = {\"prior_prec\": 60.}  # Choose any prior precision.\n",
    "prob_predictive = set_nonlin_prob_predictive(\n",
    "    prior_arguments=prior_arguments,\n",
    ")\n",
    "\n",
    "X_test = jnp.linspace(0, 8, 200).reshape(200, 1)\n",
    "pred = jax.vmap(prob_predictive)(X_test)\n",
    "pred_mean = pred[\"pred_mean\"][:, 0]\n",
    "pred_var = pred[\"pred_var\"][:, 0]\n",
    "print(pred_mean.shape, pred_var.shape)\n",
    "plot_regression_with_uncertainty(\n",
    "    train_input=train_batch[\"input\"],\n",
    "    train_target=train_batch[\"target\"],\n",
    "    X_grid=X_test,\n",
    "    Y_pred=pred_mean,\n",
    "    Y_var=pred_var,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "from laplax.eval.calibrate import (\n",
    "    evaluate_for_given_prior_arguments,\n",
    "    optimize_prior_prec,\n",
    ")\n",
    "from laplax.eval.metrics import nll_gaussian\n",
    "from laplax.eval.pushforward import (\n",
    "    lin_pred_mean,\n",
    "    lin_pred_std,\n",
    "    lin_setup,\n",
    "    set_lin_pushforward,\n",
    ")\n",
    "\n",
    "set_prob_predictive = partial(\n",
    "    set_lin_pushforward,\n",
    "    model_fn=model_fn,\n",
    "    mean_params=params,\n",
    "    posterior_fn=posterior_fn,\n",
    "    pushforward_fns=[\n",
    "        lin_setup,\n",
    "        lin_pred_mean,\n",
    "        lin_pred_std,\n",
    "    ],\n",
    ")\n",
    "\n",
    "clbr_batch = {\"input\": X_valid, \"target\": y_valid}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target: Negative Log-Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibration_objective(prior_arguments):\n",
    "    return evaluate_for_given_prior_arguments(\n",
    "        prior_arguments=prior_arguments,\n",
    "        data=clbr_batch,\n",
    "        set_prob_predictive=set_prob_predictive,\n",
    "        metric=nll_gaussian,\n",
    "    )\n",
    "\n",
    "\n",
    "prior_prec_nll_gaussian = optimize_prior_prec(\n",
    "    objective=calibration_objective,\n",
    "    log_prior_prec_min=-3.0,\n",
    "    log_prior_prec_max=3.0,\n",
    "    grid_size=50,\n",
    "    patience=50 # TODO: Remove this as a default argument.\n",
    ")\n",
    "\n",
    "print(\"Calibrated prior precision: \", prior_prec_nll_gaussian.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target: Marginal-Log Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from laplax.enums import LossFn\n",
    "from laplax.eval import marginal_log_likelihood\n",
    "\n",
    "\n",
    "def marglik_objective(prior_arguments):\n",
    "    return - marginal_log_likelihood(\n",
    "        curv_estimate,\n",
    "        prior_arguments=prior_arguments,\n",
    "        data=clbr_batch,\n",
    "        model_fn=model_fn,\n",
    "        params=params,\n",
    "        loss_fn=LossFn.MSE,\n",
    "        curv_type=curv_type,\n",
    "    )\n",
    "\n",
    "\n",
    "prior_prec_marglik = optimize_prior_prec(\n",
    "    objective=marglik_objective,\n",
    "    log_prior_prec_min=-3.0,\n",
    "    log_prior_prec_max=3.0,\n",
    "    grid_size=50,\n",
    "    patience=50  # TODO: Remove this as a default argument.\n",
    ")\n",
    "\n",
    "print(\"Calibrated prior precision: \", prior_prec_marglik.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate regression metrics on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from laplax.eval.metrics import DEFAULT_REGRESSION_METRICS\n",
    "from laplax.eval.utils import evaluate_metrics_on_dataset\n",
    "\n",
    "test_batch = {\"input\": X_test, \"target\": y_test}\n",
    "\n",
    "prob_predictive_no_clbr = set_prob_predictive(prior_arguments={\"prior_prec\": .001})\n",
    "pred_no_clbr = jax.vmap(prob_predictive_no_clbr)(X_range)\n",
    "results_no_clbr = evaluate_metrics_on_dataset(\n",
    "    pred_fn=prob_predictive_no_clbr,\n",
    "    data=test_batch,\n",
    "    metrics=DEFAULT_REGRESSION_METRICS,\n",
    "    reduce=jnp.mean,\n",
    ")\n",
    "\n",
    "prob_predictive_nll_gaussian = set_prob_predictive(\n",
    "    prior_arguments={\"prior_prec\": prior_prec_nll_gaussian}\n",
    ")\n",
    "pred_nll_gaussian = jax.vmap(prob_predictive_nll_gaussian)(X_range)\n",
    "results_nll_gaussian = evaluate_metrics_on_dataset(\n",
    "    pred_fn=prob_predictive_nll_gaussian,\n",
    "    data=test_batch,\n",
    "    metrics=DEFAULT_REGRESSION_METRICS,\n",
    "    reduce=jnp.mean,\n",
    ")\n",
    "\n",
    "prob_predictive_marglik = set_prob_predictive(\n",
    "    prior_arguments={\"prior_prec\": prior_prec_marglik}\n",
    ")\n",
    "pred_marglik = jax.vmap(prob_predictive_marglik)(X_range)\n",
    "results_marglik = evaluate_metrics_on_dataset(\n",
    "    pred_fn=prob_predictive_marglik,\n",
    "    data=test_batch,\n",
    "    metrics=DEFAULT_REGRESSION_METRICS,\n",
    "    reduce=jnp.mean,\n",
    ")\n",
    "\n",
    "\n",
    "# Create a DataFrame with the results\n",
    "results_df = pd.DataFrame({\n",
    "    'No Calibration': results_no_clbr,\n",
    "    'NLL Gaussian': results_nll_gaussian,\n",
    "    'Marginal Likelihood': results_marglik\n",
    "})\n",
    "\n",
    "# Display the table\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_multiple_regression_comparisons(\n",
    "    X_train: np.ndarray,\n",
    "    y_train: np.ndarray,\n",
    "    X_test: np.ndarray,\n",
    "    predictions_dict: dict[str, dict[str, np.ndarray]],\n",
    "    figsize: tuple = (18, 6),\n",
    "    suptitle: str = \"Comparison of Different Calibration Methods\",\n",
    "    train_label: str = \"Training Data\",\n",
    "    confidence_alpha: float = 0.3,\n",
    ") -> plt.Figure:\n",
    "    \"\"\"Create side-by-side regression plots with uncertainty for multiple methods.\n",
    "\n",
    "    Args:\n",
    "        X_train: Training input data\n",
    "        y_train: Training target data\n",
    "        X_test: Test input data\n",
    "        predictions_dict: Dictionary of dictionaries, where outer keys are method names\n",
    "                         and inner dictionaries contain 'mean' and 'std' arrays\n",
    "        figsize: Figure size as (width, height)\n",
    "        suptitle: Super title for the entire figure\n",
    "        train_label: Label for training data\n",
    "        test_label: Label for test data\n",
    "        confidence_alpha: Alpha value for confidence interval\n",
    "        save_path: Optional path to save the figure\n",
    "\n",
    "    Returns:\n",
    "        The matplotlib figure object\n",
    "    \"\"\"\n",
    "    # Create figure with subplots\n",
    "    n_methods = len(predictions_dict)\n",
    "    fig, axes = plt.subplots(1, n_methods, figsize=figsize, sharey=True)\n",
    "\n",
    "    # If only one method, make axes iterable\n",
    "    if n_methods == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    # Plot each method\n",
    "    for i, (method_name, predictions) in enumerate(predictions_dict.items()):\n",
    "        ax = axes[i]\n",
    "\n",
    "        # Get predictions\n",
    "        y_pred = predictions['mean']\n",
    "        y_std = np.sqrt(predictions.get('var', 0.0))  # Get standard deviation from variance\n",
    "\n",
    "        # Plot training data\n",
    "        ax.scatter(X_train, y_train, color='#1f77b4', alpha=0.7, s=30, label=train_label)\n",
    "\n",
    "        # Plot mean prediction\n",
    "        ax.plot(X_test, y_pred, color='#ff7f0e', label='Mean Prediction')\n",
    "\n",
    "        # Plot uncertainty if variance provided\n",
    "        if 'var' in predictions:\n",
    "            ax.fill_between(\n",
    "                X_test.flatten(),\n",
    "                (y_pred - 1.96 * y_std).flatten(),\n",
    "                (y_pred + 1.96 * y_std).flatten(),\n",
    "                color='#ff7f0e', alpha=confidence_alpha, label='95% Confidence'\n",
    "            )\n",
    "\n",
    "        # Set title and labels\n",
    "        ax.set_title(method_name, fontsize=14)\n",
    "        ax.set_xlabel('X', fontsize=12)\n",
    "        if i == 0:\n",
    "            ax.set_ylabel('y', fontsize=12)\n",
    "\n",
    "        # Add grid\n",
    "        ax.grid(linestyle='--', alpha=0.7)\n",
    "\n",
    "        # Add metrics if available\n",
    "        if 'metrics' in predictions:\n",
    "            metrics_text = \"\\n\".join([f\"{k}: {v:.4f}\" for k, v in predictions['metrics'].items()])\n",
    "            ax.text(0.05, 0.95, metrics_text, transform=ax.transAxes, \n",
    "                    verticalalignment='top', \n",
    "                    bbox={\"boxstyle\": 'round', \"facecolor\": 'white', \"alpha\": 0.8}\n",
    "            )\n",
    "\n",
    "    # Add legend to the first subplot\n",
    "    handles, labels = axes[0].get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5, 0.05), \n",
    "               ncol=min(4, len(handles)), frameon=True, fontsize=12)\n",
    "\n",
    "    # Add super title\n",
    "    fig.suptitle(suptitle, fontsize=16, y=0.98)\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout(rect=[0, 0.08, 1, 0.95])\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After running your different calibration methods and collecting results\n",
    "# Assuming you have predictions and uncertainties from different methods\n",
    "\n",
    "# Create a dictionary to hold predictions from different methods\n",
    "predictions_dict = {\n",
    "    \"No calibration\": {\n",
    "        \"mean\": pred_no_clbr[\"pred_mean\"][:, 0],\n",
    "        \"std\": np.sqrt(pred_no_clbr[\"pred_var\"][:, 0]),\n",
    "    },\n",
    "    \"NLL Gaussian\": {\n",
    "        \"mean\": pred_nll_gaussian[\"pred_mean\"][:, 0],\n",
    "        \"var\": pred_nll_gaussian[\"pred_var\"][:, 0],\n",
    "    },\n",
    "    \"Marginal Likelihood\": {\n",
    "        \"mean\": pred_marglik[\"pred_mean\"][:, 0],\n",
    "        \"var\": pred_marglik[\"pred_var\"][:, 0],\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create the comparison plot\n",
    "fig = plot_multiple_regression_comparisons(\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_range,  # Use your X_range from the notebook\n",
    "    predictions_dict=predictions_dict,\n",
    "    suptitle=\"Comparison of Laplace Approximation Methods\",\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling observation noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Registering `skerch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from skerch import linops\n",
    "from skerch.decompositions import seigh\n",
    "\n",
    "from laplax.curv import register_curvature_method\n",
    "from laplax.curv.utils import LowRankTerms, get_matvec\n",
    "from laplax.types import DType\n",
    "\n",
    "\n",
    "class JAXMV(linops.TorchLinOpWrapper):\n",
    "    def __init__(self, matvec, shape):\n",
    "        self.shape = shape\n",
    "        self.matvec = matvec\n",
    "\n",
    "    def __matmul__(self, x):\n",
    "        x_dtype = x.dtype\n",
    "        x = jnp.asarray(x.detach().cpu().numpy())\n",
    "        x = self.matvec(x)\n",
    "        return torch.tensor(np.asarray(x), dtype=x_dtype)\n",
    "\n",
    "    def __rmatmul__(self, x):\n",
    "        return self.__matmul__(x.T)\n",
    "\n",
    "\n",
    "def skerch_low_rank(\n",
    "    A,\n",
    "    *,\n",
    "    layout=None,\n",
    "    rank: int = 100,\n",
    "    return_dtype: DType = jnp.float64,\n",
    "    mv_jittable=True,\n",
    "    **kwargs,\n",
    "):\n",
    "    del kwargs\n",
    "    # Setup mv product.\n",
    "    matvec, size = get_matvec(A, layout=layout, jit=mv_jittable)\n",
    "    op = JAXMV(matvec, (size, size))\n",
    "\n",
    "    res = seigh(\n",
    "        op, op_device=\"cpu\", op_dtype=torch.float64, outer_dim=rank, inner_dim=rank\n",
    "    )\n",
    "\n",
    "    low_rank_result = LowRankTerms(\n",
    "        U=jnp.asarray((res[0] @ res[1]).detach().cpu()),\n",
    "        S=jnp.asarray(res[2].detach().cpu().numpy()),\n",
    "        scalar=jnp.asarray(0.0, dtype=return_dtype),\n",
    "    )\n",
    "    # TODO: Introduce mixed types as in other low rank methods.\n",
    "    return low_rank_result\n",
    "\n",
    "\n",
    "register_curvature_method(name=\"skerch\", create_fn=skerch_low_rank, default=\"lanczos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curv = estimate_curvature(\n",
    "    curv_type=\"skerch\",\n",
    "    mv=ggn_mv,\n",
    "    layout=params,\n",
    "    key=jax.random.key(20),\n",
    "    rank=50,\n",
    "    mv_jittable=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Posterior GP kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from laplax.eval.pushforward import set_posterior_gp_kernel\n",
    "\n",
    "prior_arguments = {\"prior_prec\": 0.1}\n",
    "\n",
    "gp_kernel, dist_state = set_posterior_gp_kernel(\n",
    "    model_fn=model_fn,\n",
    "    mean=params,\n",
    "    posterior_fn=posterior_fn,\n",
    "    prior_arguments=prior_arguments,\n",
    "    dense=True,  # If dense = False, then a kernel-vector product is returned.\n",
    "    output_layout=1,\n",
    ")\n",
    "\n",
    "X_grid = jnp.linspace(0.3, 8, 200).reshape(200, 1)\n",
    "Y_pred = model_fn(X_grid, params)[:, 0]\n",
    "\n",
    "Y_var = jax.jit(jax.vmap(lambda x: gp_kernel(x, x)))(X_grid)[:, 0, 0]\n",
    "\n",
    "plot_regression_with_uncertainty(\n",
    "    train_input=train_batch[\"input\"],\n",
    "    train_target=train_batch[\"target\"],\n",
    "    X_grid=X_grid,\n",
    "    Y_pred=Y_pred,\n",
    "    Y_var=Y_var,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Low Rank Laplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from laplax.curv.cov import create_posterior_fn\n",
    "\n",
    "# Create Posterior\n",
    "posterior_fn = create_posterior_fn(\n",
    "    \"lanczos\",\n",
    "    mv=ggn_mv,\n",
    "    layout=params,\n",
    "    key=jax.random.key(20),\n",
    "    maxiter=50,\n",
    "    mv_jittable=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from laplax.eval.pushforward import set_posterior_gp_kernel\n",
    "\n",
    "prior_arguments = {\"prior_prec\": 1.0}\n",
    "\n",
    "gp_kernel, _ = set_posterior_gp_kernel(\n",
    "    model_fn=model_fn,\n",
    "    mean=params,\n",
    "    posterior_fn=posterior_fn,\n",
    "    prior_arguments=prior_arguments,\n",
    "    dense=True,  # If dense = False, then a kernel-vector product is returned.\n",
    "    output_layout=1,\n",
    ")\n",
    "\n",
    "X_grid = jnp.linspace(0.0, 8, 200).reshape(200, 1)\n",
    "Y_pred = model_fn(X_grid, params)[:, 0]\n",
    "Y_var = jax.jit(jax.vmap(lambda x: gp_kernel(x, x)))(X_grid)[:, 0, 0]\n",
    "\n",
    "plot_regression_with_uncertainty(\n",
    "    train_input=train_batch[\"input\"],\n",
    "    train_target=train_batch[\"target\"],\n",
    "    X_grid=X_grid,\n",
    "    Y_pred=Y_pred,\n",
    "    Y_var=Y_var,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "from laplax.eval.pushforward import (\n",
    "    set_lin_pushforward,\n",
    "    lin_setup,\n",
    "    lin_pred_mean,\n",
    "    lin_pred_std,\n",
    ")\n",
    "\n",
    "from laplax.eval.calibrate import (\n",
    "    evaluate_for_given_prior_arguments,\n",
    "    optimize_prior_prec,\n",
    ")\n",
    "\n",
    "set_prob_predictive = partial(\n",
    "    set_lin_pushforward,\n",
    "    model_fn=model_fn,\n",
    "    mean_params=params,\n",
    "    posterior_fn=posterior_fn,\n",
    "    pushforward_fns=[\n",
    "        lin_setup,\n",
    "        lin_pred_mean,\n",
    "        lin_pred_std,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from laplax.eval.calibrate import calibration_metric\n",
    "\n",
    "clbr_batch = {\"input\": X_valid, \"target\": y_valid}\n",
    "\n",
    "\n",
    "def calibration_objective(prior_arguments):\n",
    "    return evaluate_for_given_prior_arguments(\n",
    "        prior_arguments=prior_arguments,\n",
    "        data=clbr_batch,\n",
    "        set_prob_predictive=set_prob_predictive,\n",
    "        metric=calibration_metric,\n",
    "    )\n",
    "\n",
    "\n",
    "prior_prec_chi_squared = optimize_prior_prec(\n",
    "    objective=calibration_objective,\n",
    "    log_prior_prec_min=-3.0,\n",
    "    log_prior_prec_max=3.0,\n",
    "    grid_size=50,\n",
    "    patience=50, # TODO: Remove this as a default argument.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from laplax.eval.metrics import nll_gaussian\n",
    "\n",
    "\n",
    "def calibration_objective(prior_arguments):\n",
    "    return evaluate_for_given_prior_arguments(\n",
    "        prior_arguments=prior_arguments,\n",
    "        data=clbr_batch,\n",
    "        set_prob_predictive=set_prob_predictive,\n",
    "        metric=nll_gaussian,\n",
    "    )\n",
    "\n",
    "\n",
    "prior_prec_nll_gaussian = optimize_prior_prec(\n",
    "    objective=calibration_objective,\n",
    "    log_prior_prec_min=-3.0,\n",
    "    log_prior_prec_max=3.0,\n",
    "    grid_size=100,\n",
    "    patience=100, # TODO: Remove this as a default argument.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "prob_predictive_no_clbr = set_prob_predictive(prior_arguments={\"prior_prec\": 1.0})\n",
    "input_points = jnp.linspace(0, 8, 200).reshape(200, 1)\n",
    "results = jax.vmap(prob_predictive_no_clbr)(input_points)\n",
    "\n",
    "\n",
    "plt.plot(input_points[:, 0], results[\"pred_mean\"], label=\"mean\")\n",
    "plt.fill_between(\n",
    "    input_points[:, 0],\n",
    "    (results[\"pred_mean\"] - 1.96 * results[\"pred_std\"])[:, 0],\n",
    "    (results[\"pred_mean\"] + 1.96 * results[\"pred_std\"])[:, 0],\n",
    "    alpha=0.2,\n",
    ")\n",
    "plt.scatter(train_batch[\"input\"][:, 0], train_batch[\"target\"], label=\"train\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "prob_predictive_nll_gaussian = set_prob_predictive(prior_arguments={\"prior_prec\": prior_prec_nll_gaussian})\n",
    "input_points = jnp.linspace(0, 8, 200).reshape(200, 1)\n",
    "results = jax.vmap(prob_predictive_nll_gaussian)(input_points)\n",
    "\n",
    "\n",
    "plt.plot(input_points[:, 0], results[\"pred_mean\"], label=\"mean\")\n",
    "plt.fill_between(\n",
    "    input_points[:, 0],\n",
    "    (results[\"pred_mean\"] - 1.96 * results[\"pred_std\"])[:, 0],\n",
    "    (results[\"pred_mean\"] + 1.96 * results[\"pred_std\"])[:, 0],\n",
    "    alpha=0.2,\n",
    ")\n",
    "plt.scatter(train_batch[\"input\"][:, 0], train_batch[\"target\"], label=\"train\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "prob_predictive_chi_squared = set_prob_predictive(prior_arguments={\"prior_prec\": prior_prec_chi_squared})\n",
    "input_points = jnp.linspace(0, 8, 200).reshape(200, 1)\n",
    "results = jax.vmap(prob_predictive_chi_squared)(input_points)\n",
    "\n",
    "\n",
    "plt.plot(input_points[:, 0], results[\"pred_mean\"], label=\"mean\")\n",
    "plt.fill_between(\n",
    "    input_points[:, 0],\n",
    "    (results[\"pred_mean\"] - 1.96 * results[\"pred_std\"])[:, 0],\n",
    "    (results[\"pred_mean\"] + 1.96 * results[\"pred_std\"])[:, 0],\n",
    "    alpha=0.2,\n",
    ")\n",
    "plt.scatter(train_batch[\"input\"][:, 0], train_batch[\"target\"], label=\"train\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from laplax.eval.utils import evaluate_metrics_on_dataset\n",
    "from laplax.eval.metrics import DEFAULT_REGRESSION_METRICS\n",
    "\n",
    "# x_test = jnp.linspace(0, 10, 200).reshape(200, 1)\n",
    "# y_test = jnp.sin(x_test)\n",
    "test_batch = {\"input\": X_test, \"target\": y_test}\n",
    "\n",
    "results_no_clbr = evaluate_metrics_on_dataset(\n",
    "    pred_fn=prob_predictive_no_clbr,\n",
    "    data=test_batch,\n",
    "    metrics=DEFAULT_REGRESSION_METRICS,\n",
    "    reduce=jnp.mean,\n",
    ")\n",
    "\n",
    "results_nll_gaussian = evaluate_metrics_on_dataset(\n",
    "    pred_fn=prob_predictive_nll_gaussian,\n",
    "    data=test_batch,\n",
    "    metrics=DEFAULT_REGRESSION_METRICS,\n",
    "    reduce=jnp.mean,\n",
    ")\n",
    "\n",
    "results_chi_squared = evaluate_metrics_on_dataset(\n",
    "    pred_fn=prob_predictive_chi_squared,\n",
    "    data=test_batch,\n",
    "    metrics=DEFAULT_REGRESSION_METRICS,\n",
    "    reduce=jnp.mean,\n",
    ")\n",
    "\n",
    "print(results_no_clbr)\n",
    "print(results_nll_gaussian)\n",
    "print(results_chi_squared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration using Marginal Log-Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from laplax.curv.cov import estimate_curvature\n",
    "from laplax.eval.likelihood import marginal_log_likelihood\n",
    "from laplax.enums import CurvApprox, LossFn\n",
    "\n",
    "curv = estimate_curvature(\n",
    "    curv_type=CurvApprox.LANCZOS,\n",
    "    mv=ggn_mv,\n",
    "    layout=params,\n",
    "    key=jax.random.key(20),\n",
    "    maxiter=50,\n",
    "    mv_jittable=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marginal_log_likelihood(\n",
    "    curv,\n",
    "    prior_arguments={\"prior_prec\": 0.001},\n",
    "    data=clbr_batch,\n",
    "    model_fn=model_fn,\n",
    "    params=params,\n",
    "    loss_fn=LossFn.MSE,\n",
    "    curv_type=CurvApprox.LANCZOS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from laplax.curv.utils import concatenate_model_and_loss_fn\n",
    "\n",
    "full_fn = concatenate_model_and_loss_fn(\n",
    "    model_fn=model_fn,\n",
    "    loss_fn=LossFn.MSE,\n",
    "    has_batch=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def calibration_objective(prior_arguments):\n",
    "    return - marginal_log_likelihood(\n",
    "        curv,\n",
    "        prior_arguments=prior_arguments,\n",
    "        data=clbr_batch,\n",
    "        model_fn=model_fn,\n",
    "        params=params,\n",
    "        loss_fn=LossFn.MSE,\n",
    "        curv_type=CurvApprox.LANCZOS,\n",
    "    )\n",
    "\n",
    "\n",
    "prior_prec_nll_gaussian = optimize_prior_prec(\n",
    "    objective=calibration_objective,\n",
    "    log_prior_prec_min=-6.0,\n",
    "    log_prior_prec_max=6.0,\n",
    "    grid_size=100,\n",
    "    patience=100,  # TODO: Remove this as a default argument.\n",
    ")\n",
    "\n",
    "results_nll_gaussian = evaluate_metrics_on_dataset(\n",
    "    pred_fn=prob_predictive_nll_gaussian,\n",
    "    data=test_batch,\n",
    "    metrics=DEFAULT_REGRESSION_METRICS,\n",
    "    reduce=jnp.mean,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Gradient Descent for calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "lr = 1e-1\n",
    "\n",
    "# Initialize prior arguments\n",
    "prior_arguments = {\"prior_prec\": jnp.array(1.0)}\n",
    "\n",
    "# Set optimizer\n",
    "optimizer = optax.adam(lr)\n",
    "\n",
    "# Initialize state\n",
    "opt_state = optimizer.init(prior_arguments)\n",
    "\n",
    "# Create data loader\n",
    "train_loader = DataLoader(X_data, y_data, batch_size=32)\n",
    "\n",
    "\n",
    "# Calibration step\n",
    "@jax.jit\n",
    "def objective_fn(prior_args, data):\n",
    "    return - marginal_log_likelihood(\n",
    "        curv,\n",
    "        prior_arguments=prior_args,\n",
    "        data=data,\n",
    "        model_fn=model_fn,\n",
    "        params=params,\n",
    "        loss_fn=LossFn.MSE,\n",
    "        curv_type=CurvApprox.LANCZOS,\n",
    "    )\n",
    "\n",
    "\n",
    "# Training loop for calibration\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    print(\"-\" * 100)\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        # Compute the objective value and its gradient with respect to prior_arguments\n",
    "        obj, grads = jax.value_and_grad(\n",
    "            lambda p: objective_fn(p, input_target_split(batch))\n",
    "        )(prior_arguments)\n",
    "\n",
    "        # Update the parameters using the optimizer\n",
    "        updates, opt_state = optimizer.update(grads, opt_state)\n",
    "        prior_arguments = optax.apply_updates(prior_arguments, updates)\n",
    "\n",
    "        # Print progress every 100 iterations\n",
    "        if i % 2 == 0:\n",
    "            print(f\"Iteration {i}: Objective = {obj}\")\n",
    "\n",
    "# Print the final prior arguments\n",
    "obj = objective_fn(prior_arguments, {\"input\": X_data, \"target\": y_data})\n",
    "print(f\"Final prior arguments: {prior_arguments}\")\n",
    "print(f\"Final objective value: {obj}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
